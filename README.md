# Gesture-Controlled AI â€“ Self Learning Project

> **Note:** This is my self-learning AI project where Iâ€™ll build gesture-based automation from scratch using Python, OpenCV, and MediaPipe. I'm documenting everything step-by-step as I learn.

---

## ğŸ” Project Goal

Build a simple system that uses hand gestures to control apps like:
- Swiping slides
- Taking screenshots
- Pausing videos
- Switching tabs/windows

## ğŸ› ï¸ Tools Iâ€™ll Learn and Use

- Python
- OpenCV
- MediaPipe
- pyautogui (for automation)

## ğŸ“… Learning Timeline

| Phase | Task |
|-------|----------------------------------------------------|
| Phase 1 | Open webcam using OpenCV |
| Phase 2 | Detect hands using MediaPipe |
| Phase 3 | Track gesture points (e.g., thumb, fingertips) |
| Phase 4 | Map gestures to real-world actions (e.g., screenshot, play/pause) |
| Phase 5 | Combine everything into one functional script |
| Phase 6 | Polish code, update GitHub, and write final README |


---

## ğŸ§  My Learning Logs

- [ ] Webcam opened successfully âœ…
- [ ] Hand tracking added âœ…
- [ ] Gesture mapped to action âœ…
- [ ] First demo recorded ğŸ“¹
